# Ski Lift & Slope Status Dashboard

A Python-based scraping and monitoring system that collects ski lift and slope opening statuses from local ski resort websites (Vaud & Valais, Switzerland) and visualizes them using Grafana.

The system is designed for **low-frequency scraping (2â€“3Ã— per day)**, high reliability, and visually rich dashboards with dark themes, gauges, and status indicators.

---

## ğŸ—ï¸ Architecture Overview

Ski Resort Websites
â†“
Python Selenium Scrapers
â†“
Orchestrator / Scheduler
â†“
PostgreSQL Database
â†“
Grafana Dashboards


---

## ğŸ§± Components

### 1ï¸âƒ£ Scraper Layer (Python + Selenium)
- One scraper module per resort
- Handles JavaScript-heavy pages
- Normalizes lift and slope statuses
- Outputs structured data only (no DB logic)

**Responsibilities**
- Open resort status pages
- Parse lift and slope data
- Normalize names and statuses
- Return clean Python dictionaries

---

### 2ï¸âƒ£ Orchestrator / Scheduler
- Controls when scraping runs
- Executes all enabled resort scrapers
- Handles retries, logging, and validation
- Writes results to the database

**Scheduling**
- 2â€“3 runs per day
- Implemented using:
  - Cron (recommended)
  - or APScheduler (optional)

---

### 3ï¸âƒ£ Database (PostgreSQL)
Stores current and historical lift/slope statuses.

**Core Tables**
- `resorts`
- `lifts`
- `slopes`
- `statuses`

Supports:
- Historical tracking
- Grafana SQL queries
- Future expansion (snow depth, weather, alerts)

---

### 4ï¸âƒ£ Grafana
- Read-only visualization layer
- Auto-refresh every 5â€“15 minutes
- Dark theme by default

**Panels**
- Status cards (open / closed)
- Gauges (% lifts open)
- Tables (per-resort breakdowns)

---

### 5ï¸âƒ£ Optional API Layer (Future)
FastAPI service for:
- External access
- Mobile apps
- Public endpoints

Grafana connects directly to the database (API not required initially).

---

## ğŸ—‚ï¸ Project Structure



ski-dashboard/
â”œâ”€â”€ scraper/
â”‚ â”œâ”€â”€ base/
â”‚ â”‚ â”œâ”€â”€ selenium_driver.py
â”‚ â”‚ â”œâ”€â”€ scraper_base.py
â”‚ â”‚ â””â”€â”€ utils.py
â”‚ â”œâ”€â”€ resorts/
â”‚ â”‚ â”œâ”€â”€ verbier.py
â”‚ â”‚ â”œâ”€â”€ villars.py
â”‚ â”‚ â”œâ”€â”€ leyson.py
â”‚ â”‚ â””â”€â”€ crans_montana.py
â”‚ â””â”€â”€ run_scraper.py
â”‚
â”œâ”€â”€ orchestrator/
â”‚ â”œâ”€â”€ scheduler.py
â”‚ â””â”€â”€ tasks.py
â”‚
â”œâ”€â”€ db/
â”‚ â”œâ”€â”€ schema.sql
â”‚ â””â”€â”€ migrations/
â”‚
â”œâ”€â”€ grafana/
â”‚ â”œâ”€â”€ dashboards/
â”‚ â””â”€â”€ provisioning/
â”‚
â”œâ”€â”€ docker/
â”‚ â”œâ”€â”€ docker-compose.yml
â”‚ â”œâ”€â”€ grafana/
â”‚ â””â”€â”€ postgres/
â”‚
â”œâ”€â”€ logs/
â”œâ”€â”€ config/
â”‚ â””â”€â”€ settings.yaml
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## ğŸ”„ Data Flow

1. Scheduler triggers scraper
2. Selenium scrapes resort websites
3. Data is normalized and validated
4. Database is updated (UPSERT)
5. Grafana queries database
6. Dashboards refresh automatically

---

## ğŸ³ Deployment

- All services run via Docker
- Easy local development and cloud deployment
- Reproducible environment

---

## âš ï¸ Notes & Best Practices

- Respect resort website terms of service
- Use reasonable delays and caching
- Log all scrape attempts
- Detect DOM changes and fail gracefully

---

## ğŸš€ Next Steps

- Implement base Selenium scraper
- Create database schema
- Configure Grafana data source
- Design first dashboard
